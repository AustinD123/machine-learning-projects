{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3997b9c8-a746-4263-8d76-791b360c5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fea45e3-3d81-4dad-a338-370eb537c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55420a91-c4c1-4322-b4af-00fc459d80f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data=datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5ca310-c209-47bc-a41c-b7bc3c654e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data=datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5989e017-e879-4004-a745-c3e3278afad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader=DataLoader(training_data,32,True, drop_last=True)\n",
    "test_dataloader=DataLoader(test_data,32,False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae60c2e5-f496-4cb4-bf2c-0ea94b8e668d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, labels=next(iter(train_dataloader))\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92efb4da-9344-4764-bb70-b318bc1ca866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2657c79e-da6e-415e-a6d6-79ffdf9aacb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, \n",
    "                      stride=1, \n",
    "                      padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, \n",
    "                      stride=1, \n",
    "                      padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*64 , \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "   \n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "       \n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model=CIFAR10(input_shape=3,hidden_units=10,output_shape=len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01032508-c981-4089-812f-4680c32c4ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0293,  0.0322, -0.0461,  0.0474, -0.0055,  0.0732, -0.0368,  0.1202,\n",
       "          0.1034, -0.0642]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy=torch.randn([1,3,32,32])\n",
    "model(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709f079b-7d3d-4dda-8f28-8d9dfce95455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "from pathlib import Path \n",
    "\n",
    "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "  print(\"helper_functions.py already exists, skipping download\")\n",
    "else:\n",
    "  print(\"Downloading helper_functions.py\")\n",
    "  # Note: you need the \"raw\" GitHub URL for this to work\n",
    "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "  with open(\"helper_functions.py\", \"wb\") as f:\n",
    "    f.write(request.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8516b4de-9462-4755-98ec-996337dc27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "212fca6c-f644-460a-8992-d09c2b4dfc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-------\n",
      "Looked at 0/50000 samples\n",
      "Looked at 12800/50000 samples\n",
      "Looked at 25600/50000 samples\n",
      "Looked at 38400/50000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 1/3 [00:37<01:14, 37.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 2.30377 | Test loss: 2.30292, Test acc: 9.99%\n",
      "\n",
      "Epoch: 1\n",
      "-------\n",
      "Looked at 0/50000 samples\n",
      "Looked at 12800/50000 samples\n",
      "Looked at 25600/50000 samples\n",
      "Looked at 38400/50000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [01:14<00:37, 37.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 2.30345 | Test loss: 2.30324, Test acc: 10.01%\n",
      "\n",
      "Epoch: 2\n",
      "-------\n",
      "Looked at 0/50000 samples\n",
      "Looked at 12800/50000 samples\n",
      "Looked at 25600/50000 samples\n",
      "Looked at 38400/50000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:53<00:00, 37.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 2.30336 | Test loss: 2.30305, Test acc: 10.01%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-------\")\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "    \n",
    "    train_loss = train_loss / len(train_dataloader)  # Non-in-place division\n",
    "    \n",
    "    # Evaluation loop\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            test_pred = model(X)\n",
    "            test_loss += loss_fn(test_pred, y).item()  # Use .item() to get a Python number\n",
    "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))  # Use .item() here as well\n",
    "    \n",
    "    test_loss = test_loss / len(test_dataloader)  # Non-in-place division\n",
    "    test_acc = test_acc / len(test_dataloader)    # Non-in-place division\n",
    "    \n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6fea7-3904-402e-8556-2e2fc0c530ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
