{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e2751a-001f-4bfb-96e6-c236b8ab76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7097ba-1180-4bc9-9e1e-450db76fb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=r\"C:\\Users\\austi\\Downloads\\Flickr8k_Dataset\\Flicker8k_Dataset\"\n",
    "captions_path=r\"C:\\Users\\austi\\Downloads\\Flickr8k_text\\Flickr8k.lemma.token.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d35290-71d1-487c-bdcc-f73032a5a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(captions_path, sep='\\t', header=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1f4350-c0b9-4985-a66c-71e94e62e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['image_filename', 'caption_id']] = df[0].str.split('#', expand=True)\n",
    "\n",
    "df = df.drop(columns=[0])\n",
    "\n",
    "df.columns = ['caption', 'image_filename', 'caption_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a096b7-e2fc-4719-8754-06318134ed72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>caption_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man in street racer armor be examine the tir...</td>\n",
       "      <td>1305564994_00513f9a5b.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two racer drive a white bike down a road .</td>\n",
       "      <td>1305564994_00513f9a5b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two motorist be ride along on their vehicle th...</td>\n",
       "      <td>1305564994_00513f9a5b.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two person be in a small race car drive by a g...</td>\n",
       "      <td>1305564994_00513f9a5b.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two person in race uniform in a street car .</td>\n",
       "      <td>1305564994_00513f9a5b.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40455</th>\n",
       "      <td>A girl in a pool wear goggles and surround by ...</td>\n",
       "      <td>989754491_7e53fb4586.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40456</th>\n",
       "      <td>A girl in green goggles in a pool with three o...</td>\n",
       "      <td>989754491_7e53fb4586.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40457</th>\n",
       "      <td>A red haired girl make a peace sign be wear ne...</td>\n",
       "      <td>989754491_7e53fb4586.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40458</th>\n",
       "      <td>A redheaded girl offer a peace sign as she swi...</td>\n",
       "      <td>989754491_7e53fb4586.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40459</th>\n",
       "      <td>A young girl with goggles and floaties pose fo...</td>\n",
       "      <td>989754491_7e53fb4586.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40460 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 caption  \\\n",
       "0      A man in street racer armor be examine the tir...   \n",
       "1             Two racer drive a white bike down a road .   \n",
       "2      Two motorist be ride along on their vehicle th...   \n",
       "3      Two person be in a small race car drive by a g...   \n",
       "4           Two person in race uniform in a street car .   \n",
       "...                                                  ...   \n",
       "40455  A girl in a pool wear goggles and surround by ...   \n",
       "40456  A girl in green goggles in a pool with three o...   \n",
       "40457  A red haired girl make a peace sign be wear ne...   \n",
       "40458  A redheaded girl offer a peace sign as she swi...   \n",
       "40459  A young girl with goggles and floaties pose fo...   \n",
       "\n",
       "                  image_filename caption_id  \n",
       "0      1305564994_00513f9a5b.jpg          0  \n",
       "1      1305564994_00513f9a5b.jpg          1  \n",
       "2      1305564994_00513f9a5b.jpg          2  \n",
       "3      1305564994_00513f9a5b.jpg          3  \n",
       "4      1305564994_00513f9a5b.jpg          4  \n",
       "...                          ...        ...  \n",
       "40455   989754491_7e53fb4586.jpg          0  \n",
       "40456   989754491_7e53fb4586.jpg          1  \n",
       "40457   989754491_7e53fb4586.jpg          2  \n",
       "40458   989754491_7e53fb4586.jpg          3  \n",
       "40459   989754491_7e53fb4586.jpg          4  \n",
       "\n",
       "[40460 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "509e7aea-d9ae-4483-b063-20377de65c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man in street racer armor be examine the tire of another racer 's motorbike .\n",
      "Two racer drive a white bike down a road .\n",
      "Two motorist be ride along on their vehicle that be oddly design and color .\n",
      "Two person be in a small race car drive by a green hill .\n",
      "Two person in race uniform in a street car .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de40b017-d1f2-4148-a210-982ccb433596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dc9130-6c46-4b08-a4f6-2a449d705ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption=df[\"caption\"][0]\n",
    "caption_tokens = tokenizer(caption, padding='max_length', max_length=30, truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d52394-42f9-4140-b355-e6f24aac0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=caption_tokens[\"input_ids\"].squeeze().clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e9b61f-3b01-4729-b0e3-ae47e0ad49c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1037,  2158,  1999,  2395, 14878,  8177,  2022, 11628,  1996,\n",
       "        12824,  1997,  2178, 14878,  1005,  1055,  5013,  5638,  3489,  1012,\n",
       "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "519b5f5f-d9ed-45a7-80be-2c8d57e199ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "class data_loader:\n",
    "    def __init__(self,images_path,captions_path,tokenizer,transform=None):\n",
    "        self.images_path=images_path\n",
    "        self.captions_path=captions_path\n",
    "        self.tokenizer=tokenizer\n",
    "        self.transform=transform\n",
    "        self.df = pd.read_csv(captions_path, sep='\\t', header=None)  \n",
    "        self.df[['image_filename', 'caption_id']] = self.df[0].str.split('#', expand=True)\n",
    "        self.df = self.df.drop(columns=[0])\n",
    "        self.df.columns = ['caption', 'image_filename', 'caption_id']\n",
    "    def __getitem__(self,idx):\n",
    "        self.image_name=self.df[\"image_filename\"][idx]\n",
    "        self.caption_id=self.df[\"caption_id\"][idx]\n",
    "        self.img_path=f\"{self.images_path}\\\\{self.image_name}\"\n",
    "        self.image=Image.open(self.img_path).convert(\"RGB\")\n",
    "        self.caption=self.df[\"caption\"][idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(self.image)\n",
    "\n",
    "        caption_tokens = self.tokenizer(self.caption, padding='max_length', max_length=30, truncation=True, return_tensors=\"pt\")\n",
    "        caption_tensor = caption_tokens['input_ids'].squeeze() \n",
    "\n",
    "        return image, caption_tensor\n",
    "    \n",
    "def custom_collate_fn(batch):\n",
    "    images, captions = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    captions = torch.nn.utils.rnn.pad_sequence(captions, batch_first=True, padding_value=0)\n",
    "    return images, captions\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "images_path=r\"C:\\Users\\austi\\Downloads\\Flickr8k_Dataset\\Flicker8k_Dataset\"\n",
    "captions_path=r\"C:\\Users\\austi\\Downloads\\Flickr8k_text\\Flickr8k.lemma.token.txt\"\n",
    "dataset = data_loader(images_path=images_path, captions_path=captions_path, tokenizer=tokenizer, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b6694c8-4b63-4b49-bc2f-313801872f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3451, 0.3294, 0.3529,  ..., 0.3647, 0.3529, 0.3608],\n",
       "          [0.3569, 0.3059, 0.3059,  ..., 0.3608, 0.3686, 0.3804],\n",
       "          [0.3843, 0.3451, 0.3725,  ..., 0.3490, 0.3804, 0.3882],\n",
       "          ...,\n",
       "          [0.6745, 0.6863, 0.7059,  ..., 0.7412, 0.7569, 0.7608],\n",
       "          [0.7020, 0.7137, 0.7059,  ..., 0.7216, 0.7216, 0.7294],\n",
       "          [0.7137, 0.7137, 0.7255,  ..., 0.7176, 0.7294, 0.7176]],\n",
       " \n",
       "         [[0.3725, 0.3647, 0.3569,  ..., 0.3647, 0.3451, 0.3451],\n",
       "          [0.3765, 0.3373, 0.3255,  ..., 0.3686, 0.3686, 0.3765],\n",
       "          [0.3765, 0.3569, 0.3843,  ..., 0.3765, 0.3961, 0.4039],\n",
       "          ...,\n",
       "          [0.6706, 0.6824, 0.7020,  ..., 0.7373, 0.7529, 0.7569],\n",
       "          [0.6980, 0.7098, 0.7020,  ..., 0.7176, 0.7176, 0.7255],\n",
       "          [0.7098, 0.7137, 0.7216,  ..., 0.7059, 0.7255, 0.7137]],\n",
       " \n",
       "         [[0.1647, 0.1490, 0.1451,  ..., 0.1647, 0.1686, 0.1804],\n",
       "          [0.1843, 0.1373, 0.1294,  ..., 0.1843, 0.2039, 0.2196],\n",
       "          [0.2157, 0.1608, 0.1765,  ..., 0.1529, 0.2000, 0.2196],\n",
       "          ...,\n",
       "          [0.6549, 0.6627, 0.6863,  ..., 0.7333, 0.7373, 0.7412],\n",
       "          [0.6824, 0.6941, 0.6902,  ..., 0.7059, 0.6980, 0.7059],\n",
       "          [0.6941, 0.6941, 0.7176,  ..., 0.6902, 0.7020, 0.6941]]]),\n",
       " tensor([  101,  2048, 14878,  3298,  1037,  2317,  7997,  2091,  1037,  2346,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3833e-b7f3-406a-8bac-f53c0956b1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
